{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-download-images-from-google-photos-using-python-and-photos-library-api-6f9c1e60a3f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from google_auth_oauthlib.flow import Flow, InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "#from googleapiclient.http import MediaFileUpload\n",
    "from google.auth.transport.requests import Request\n",
    "import requests\n",
    "\n",
    "class GooglePhotosApi:\n",
    "    def __init__(self,\n",
    "                 api_name = 'photoslibrary',\n",
    "                 client_secret_file= r'./credentials/client_secret.json',\n",
    "                 api_version = 'v1',\n",
    "                 scopes = ['https://www.googleapis.com/auth/photoslibrary']):\n",
    "        '''\n",
    "        Args:\n",
    "            client_secret_file: string, location where the requested credentials are saved\n",
    "            api_version: string, the version of the service\n",
    "            api_name: string, name of the api e.g.\"docs\",\"photoslibrary\",...\n",
    "            api_version: version of the api\n",
    "\n",
    "        Return:\n",
    "            service:\n",
    "        '''\n",
    "\n",
    "        self.api_name = api_name\n",
    "        self.client_secret_file = client_secret_file\n",
    "        self.api_version = api_version\n",
    "        self.scopes = scopes\n",
    "        self.cred_pickle_file = f'./credentials/token_{self.api_name}_{self.api_version}.pickle'\n",
    "\n",
    "        self.cred = None\n",
    "\n",
    "    def run_local_server(self):\n",
    "        # is checking if there is already a pickle file with relevant credentials\n",
    "        if os.path.exists(self.cred_pickle_file):\n",
    "            with open(self.cred_pickle_file, 'rb') as token:\n",
    "                self.cred = pickle.load(token)\n",
    "\n",
    "        # if there is no pickle file with stored credentials, create one using google_auth_oauthlib.flow\n",
    "        if not self.cred or not self.cred.valid:\n",
    "            if self.cred and self.cred.expired and self.cred.refresh_token:\n",
    "                self.cred.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(self.client_secret_file, self.scopes)\n",
    "                self.cred = flow.run_local_server()\n",
    "\n",
    "            with open(self.cred_pickle_file, 'wb') as token:\n",
    "                pickle.dump(self.cred, token)\n",
    "        \n",
    "        return self.cred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize photos api and create service\n",
    "google_photos_api = GooglePhotosApi()\n",
    "creds = google_photos_api.run_local_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AF474M2R3WSrxhJsjobPgQuTOxKdwmEVhaQkOmmHqBzxZQw8q2lMK_k0658rBKYVxqQZMUFUetpHYMHGjX9q_zYqy9cKOlDu8w'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Listing all Albums:\n",
    "def getAlbum(album_name):\n",
    "    album_url = \"https://photoslibrary.googleapis.com/v1/sharedAlbums\"\n",
    "    headers = {\n",
    "            'content-type': 'application/json',\n",
    "            'Authorization': 'Bearer {}'.format(creds.token)\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        res = requests.request(\"GET\",album_url, headers=headers)\n",
    "    except:\n",
    "        print('Request error')\n",
    "    json_result = res.json()\n",
    "    print(res.status_code)\n",
    "\n",
    "    for i in range(0, len(json_result[\"sharedAlbums\"])) :\n",
    "        if json_result[\"sharedAlbums\"][i]['title'] == album_name :\n",
    "            return json_result[\"sharedAlbums\"][i]['id']\n",
    "    print(\"Album not found.\")\n",
    "    return None\n",
    "\n",
    "album_id = getAlbum(\"Sync Flickr\")\n",
    "album_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following API call lists all the items to be downloaded. if this number exceeds 100, then data will be missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def get_response_from_medium_api(year, month, day, album_id=None):\n",
    "    url = 'https://photoslibrary.googleapis.com/v1/mediaItems:search'\n",
    "    \n",
    "    payload = {\n",
    "                \"filters\": {\n",
    "                  \"dateFilter\": {\n",
    "                    \"dates\": [\n",
    "                      {\n",
    "                        \"day\": day,\n",
    "                        \"month\": month,\n",
    "                        \"year\": year\n",
    "                      }\n",
    "                    ]\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "    headers = {\n",
    "        'content-type': 'application/json',\n",
    "        'Authorization': 'Bearer {}'.format(creds.token)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        res = requests.request(\"POST\", url, data=json.dumps(payload), headers=headers)\n",
    "    except:\n",
    "        print('Request error') \n",
    "    \n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                             id  \\\n",
       " creationTime  AF474M1fX_l2CbhuU3t6K2CajGS4JSy602RpE7pYLmWhHd...   \n",
       " creationTime  AF474M0PQAr0pVLrONijGAW6P14GA2qyyA3LD9JTypKRfu...   \n",
       " \n",
       "                                                      productUrl  \\\n",
       " creationTime  https://photos.google.com/lr/photo/AF474M1fX_l...   \n",
       " creationTime  https://photos.google.com/lr/photo/AF474M0PQAr...   \n",
       " \n",
       "                                                         baseUrl    mimeType  \\\n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_bhU...  image/jpeg   \n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_aDA...  image/jpeg   \n",
       " \n",
       "                       creationTime                       filename  \n",
       " creationTime  2022-12-21T16:47:16Z  PXL_20221221_164716420.MP.jpg  \n",
       " creationTime  2022-12-21T16:47:13Z     PXL_20221221_164713657.jpg  ,\n",
       "                                                              id  \\\n",
       " creationTime  AF474M1fX_l2CbhuU3t6K2CajGS4JSy602RpE7pYLmWhHd...   \n",
       " creationTime  AF474M0PQAr0pVLrONijGAW6P14GA2qyyA3LD9JTypKRfu...   \n",
       " \n",
       "                                                      productUrl  \\\n",
       " creationTime  https://photos.google.com/lr/photo/AF474M1fX_l...   \n",
       " creationTime  https://photos.google.com/lr/photo/AF474M0PQAr...   \n",
       " \n",
       "                                                         baseUrl    mimeType  \\\n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_bhU...  image/jpeg   \n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_aDA...  image/jpeg   \n",
       " \n",
       "                       creationTime                       filename  \n",
       " creationTime  2022-12-21T16:47:16Z  PXL_20221221_164716420.MP.jpg  \n",
       " creationTime  2022-12-21T16:47:13Z     PXL_20221221_164713657.jpg  )"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_of_media_items(year, month, day, album_id, media_items_df):\n",
    "    '''\n",
    "    Args:\n",
    "        year, month, day, album_id: day for the filter of the API call \n",
    "        media_items_df: existing data frame with all find media items so far\n",
    "    Return:\n",
    "        media_items_df: media items data frame extended by the articles found for the specified tag\n",
    "        items_df: media items uploaded on specified date\n",
    "    '''\n",
    "\n",
    "    items_list_df = pd.DataFrame()\n",
    "    \n",
    "    # create request for specified date\n",
    "    response = get_response_from_medium_api(year, month, day, album_id)\n",
    "\n",
    "    try:\n",
    "        for item in response.json()['mediaItems']:\n",
    "            items_df = pd.DataFrame(item)\n",
    "            items_df = items_df.rename(columns={\"mediaMetadata\": \"creationTime\"})\n",
    "            items_df.set_index('creationTime')\n",
    "            items_df = items_df[items_df.index == 'creationTime']\n",
    "\n",
    "            #append the existing media_items data frame\n",
    "            items_list_df = pd.concat([items_list_df, items_df])\n",
    "            media_items_df = pd.concat([media_items_df, items_df])\n",
    "    \n",
    "    except:\n",
    "        print(response.text)\n",
    "\n",
    "    return(items_list_df, media_items_df)\n",
    "\n",
    "media_items_df = pd.DataFrame()\n",
    "list_of_media_items(2022, 12, 21, album_id, media_items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2022-12-28', '2022-12-29', '2022-12-30', '2022-12-31',\n",
      "               '2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n",
      "               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "200\n",
      "Downloaded items for date: 2022 / 12 / 28\n",
      "Downloaded items for date: 2022 / 12 / 29\n",
      "{}\n",
      "\n",
      "No media items found for date: 2022 / 12 / 30\n",
      "{}\n",
      "\n",
      "No media items found for date: 2022 / 12 / 31\n",
      "Downloaded items for date: 2023 / 1 / 1\n",
      "{}\n",
      "\n",
      "No media items found for date: 2023 / 1 / 2\n",
      "{}\n",
      "\n",
      "No media items found for date: 2023 / 1 / 3\n",
      "{}\n",
      "\n",
      "No media items found for date: 2023 / 1 / 4\n",
      "{}\n",
      "\n",
      "No media items found for date: 2023 / 1 / 5\n",
      "{}\n",
      "\n",
      "No media items found for date: 2023 / 1 / 6\n",
      "{}\n",
      "\n",
      "No media items found for date: 2023 / 1 / 7\n",
      "{}\n",
      "\n",
      "No media items found for date: 2023 / 1 / 8\n"
     ]
    }
   ],
   "source": [
    "# getting data for a aspecific date up to now\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta, datetime\n",
    "import requests\n",
    "\n",
    "# Images should only be downloaded if they are not already available in downloads\n",
    "# Herefor the following code snippet, creates a list with all filenames in the /downloads/ folder\n",
    "files_list = os.listdir(r'./downloads')\n",
    "files_list_df = pd.DataFrame(files_list)\n",
    "files_list_df = files_list_df.rename(columns={0: \"filename\"})\n",
    "files_list_df.head(2)\n",
    "\n",
    "# create a list with all dates between start date and today\n",
    "sdate = date(2022,12,28)   # start date\n",
    "edate = date.today()\n",
    "date_list = pd.date_range(sdate,edate-timedelta(days=1),freq='d')\n",
    "print(date_list)\n",
    "\n",
    "# name of the album\n",
    "album_id = getAlbum(\"Sync Flickr\")\n",
    "\n",
    "media_items_df = pd.DataFrame()\n",
    "\n",
    "for date in date_list:\n",
    "    \n",
    "    # get a list with all media items for specified date (year, month, day)\n",
    "    items_df, media_items_df = list_of_media_items(year = date.year, month = date.month, day = date.day, album_id=album_id,  media_items_df = media_items_df)\n",
    "\n",
    "    if len(items_df) > 0:\n",
    "        # full outer join of items_df and files_list_df, the result is a list of items of the given \n",
    "        #day that have not been downloaded yet\n",
    "        items_not_yet_downloaded_df = pd.merge(items_df, files_list_df,on='filename',how='left')\n",
    "        items_not_yet_downloaded_df.head(2)\n",
    "\n",
    "        # download all items in items_not_yet_downloaded\n",
    "        for index, item in items_not_yet_downloaded_df.iterrows():\n",
    "            url = item.baseUrl\n",
    "            response = requests.get(url)\n",
    "\n",
    "            file_name = item.filename\n",
    "            destination_folder = './downloads/'\n",
    "\n",
    "            with open(os.path.join(destination_folder, file_name), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "                f.close()\n",
    "                \n",
    "        print(f'Downloaded items for date: {date.year} / {date.month} / {date.day}')\n",
    "    else:\n",
    "        print(f'No media items found for date: {date.year} / {date.month} / {date.day}')\n",
    "            \n",
    "#save a list of all media items to a csv file\n",
    "current_datetime = str(datetime.now())\n",
    "filename = f'item-list-{current_datetime}.csv'\n",
    "\n",
    "#save a list with all items in specified time frame\n",
    "media_items_df.to_csv(f'./media_items_list/{filename}', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('photo_sync')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "993c687acff4d36a92770ecb368a1e4daa4eb69b5430147f4a90e2b91c6cb5f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
