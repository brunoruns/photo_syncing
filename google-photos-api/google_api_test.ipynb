{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-download-images-from-google-photos-using-python-and-photos-library-api-6f9c1e60a3f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from google_auth_oauthlib.flow import Flow, InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "#from googleapiclient.http import MediaFileUpload\n",
    "from google.auth.transport.requests import Request\n",
    "import requests\n",
    "\n",
    "class GooglePhotosApi:\n",
    "    def __init__(self,\n",
    "                 api_name = 'photoslibrary',\n",
    "                 client_secret_file= r'./credentials/client_secret.json',\n",
    "                 api_version = 'v1',\n",
    "                 scopes = ['https://www.googleapis.com/auth/photoslibrary']):\n",
    "        '''\n",
    "        Args:\n",
    "            client_secret_file: string, location where the requested credentials are saved\n",
    "            api_version: string, the version of the service\n",
    "            api_name: string, name of the api e.g.\"docs\",\"photoslibrary\",...\n",
    "            api_version: version of the api\n",
    "\n",
    "        Return:\n",
    "            service:\n",
    "        '''\n",
    "\n",
    "        self.api_name = api_name\n",
    "        self.client_secret_file = client_secret_file\n",
    "        self.api_version = api_version\n",
    "        self.scopes = scopes\n",
    "        self.cred_pickle_file = f'./credentials/token_{self.api_name}_{self.api_version}.pickle'\n",
    "\n",
    "        self.cred = None\n",
    "\n",
    "    def run_local_server(self):\n",
    "        # is checking if there is already a pickle file with relevant credentials\n",
    "        if os.path.exists(self.cred_pickle_file):\n",
    "            with open(self.cred_pickle_file, 'rb') as token:\n",
    "                self.cred = pickle.load(token)\n",
    "\n",
    "        # if there is no pickle file with stored credentials, create one using google_auth_oauthlib.flow\n",
    "        if not self.cred or not self.cred.valid:\n",
    "            if self.cred and self.cred.expired and self.cred.refresh_token:\n",
    "                self.cred.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(self.client_secret_file, self.scopes)\n",
    "                self.cred = flow.run_local_server()\n",
    "\n",
    "            with open(self.cred_pickle_file, 'wb') as token:\n",
    "                pickle.dump(self.cred, token)\n",
    "        \n",
    "        return self.cred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize photos api and create service\n",
    "google_photos_api = GooglePhotosApi()\n",
    "creds = google_photos_api.run_local_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AF474M2R3WSrxhJsjobPgQuTOxKdwmEVhaQkOmmHqBzxZQw8q2lMK_k0658rBKYVxqQZMUFUetpHYMHGjX9q_zYqy9cKOlDu8w'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Listing all Albums:\n",
    "def getAlbum(album_name):\n",
    "    album_url = \"https://photoslibrary.googleapis.com/v1/sharedAlbums\"\n",
    "    headers = {\n",
    "            'content-type': 'application/json',\n",
    "            'Authorization': 'Bearer {}'.format(creds.token)\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        res = requests.request(\"GET\",album_url, headers=headers)\n",
    "    except:\n",
    "        print('Request error')\n",
    "    json_result = res.json()\n",
    "    print(res.status_code)\n",
    "\n",
    "    for i in range(0, len(json_result[\"sharedAlbums\"])) :\n",
    "        if json_result[\"sharedAlbums\"][i]['title'] == album_name :\n",
    "            return json_result[\"sharedAlbums\"][i]['id']\n",
    "    print(\"Album not found.\")\n",
    "    return None\n",
    "\n",
    "album_id = getAlbum(\"Sync Flickr\")\n",
    "album_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following API call lists all the items to be downloaded. if this number exceeds 100, then data will be missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def get_response_from_medium_api(year, month, day, album_id=None):\n",
    "    url = 'https://photoslibrary.googleapis.com/v1/mediaItems:search'\n",
    "    \n",
    "    payload = {\n",
    "                \"filters\": {\n",
    "                  \"dateFilter\": {\n",
    "                    \"dates\": [\n",
    "                      {\n",
    "                        \"day\": day,\n",
    "                        \"month\": month,\n",
    "                        \"year\": year\n",
    "                      }\n",
    "                    ]\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "    headers = {\n",
    "        'content-type': 'application/json',\n",
    "        'Authorization': 'Bearer {}'.format(creds.token)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        res = requests.request(\"POST\", url, data=json.dumps(payload), headers=headers)\n",
    "    except:\n",
    "        print('Request error') \n",
    "    \n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                             id  \\\n",
       " creationTime  AF474M3ezZGwcB5abyQRhiHwCgTMH8J4wh3_PRMZoJGq8h...   \n",
       " creationTime  AF474M3xGokn5b7w1NeRFvOh9er_YPd9lU3OshXBT3_wJn...   \n",
       " creationTime  AF474M0GuKv_vECh-b93GvDpzGX1P1uzfvLGuKRT4cDHHh...   \n",
       " creationTime  AF474M0rT6pLhjLwROPXZgCbx50nq1ti6MOyMPZG61fTlm...   \n",
       " creationTime  AF474M1CaONcZ2WqjWAPwoL8bdVxeAscHbWwfDsco5AiS8...   \n",
       " creationTime  AF474M0HrxY-mp6oTzclmz_ZaHjphzmV-Tfc4vzM1Aspdx...   \n",
       " \n",
       "                                                      productUrl  \\\n",
       " creationTime  https://photos.google.com/lr/photo/AF474M3ezZG...   \n",
       " creationTime  https://photos.google.com/lr/photo/AF474M3xGok...   \n",
       " creationTime  https://photos.google.com/lr/photo/AF474M0GuKv...   \n",
       " creationTime  https://photos.google.com/lr/photo/AF474M0rT6p...   \n",
       " creationTime  https://photos.google.com/lr/photo/AF474M1CaON...   \n",
       " creationTime  https://photos.google.com/lr/photo/AF474M0HrxY...   \n",
       " \n",
       "                                                         baseUrl    mimeType  \\\n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_aqb...  image/jpeg   \n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_Yzb...  image/jpeg   \n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_Z9J...  image/jpeg   \n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_YNc...   video/mp4   \n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_Yr6...  image/jpeg   \n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_Zee...  image/jpeg   \n",
       " \n",
       "                       creationTime                             filename  \n",
       " creationTime  2023-01-28T16:56:14Z           PXL_20230128_165614133.jpg  \n",
       " creationTime  2023-01-28T16:56:11Z        PXL_20230128_165611657.MP.jpg  \n",
       " creationTime  2023-01-28T16:56:02Z        PXL_20230128_165602548.MP.jpg  \n",
       " creationTime  2023-01-28T11:20:03Z           PXL_20230128_111935877.mp4  \n",
       " creationTime  2023-01-28T08:34:13Z  PXL_20230128_083413299.PORTRAIT.jpg  \n",
       " creationTime  2023-01-28T08:34:05Z  PXL_20230128_083405553.PORTRAIT.jpg  ,\n",
       "                                                              id  \\\n",
       " creationTime  AF474M3ezZGwcB5abyQRhiHwCgTMH8J4wh3_PRMZoJGq8h...   \n",
       " creationTime  AF474M3xGokn5b7w1NeRFvOh9er_YPd9lU3OshXBT3_wJn...   \n",
       " creationTime  AF474M0GuKv_vECh-b93GvDpzGX1P1uzfvLGuKRT4cDHHh...   \n",
       " creationTime  AF474M0rT6pLhjLwROPXZgCbx50nq1ti6MOyMPZG61fTlm...   \n",
       " creationTime  AF474M1CaONcZ2WqjWAPwoL8bdVxeAscHbWwfDsco5AiS8...   \n",
       " creationTime  AF474M0HrxY-mp6oTzclmz_ZaHjphzmV-Tfc4vzM1Aspdx...   \n",
       " \n",
       "                                                      productUrl  \\\n",
       " creationTime  https://photos.google.com/lr/photo/AF474M3ezZG...   \n",
       " creationTime  https://photos.google.com/lr/photo/AF474M3xGok...   \n",
       " creationTime  https://photos.google.com/lr/photo/AF474M0GuKv...   \n",
       " creationTime  https://photos.google.com/lr/photo/AF474M0rT6p...   \n",
       " creationTime  https://photos.google.com/lr/photo/AF474M1CaON...   \n",
       " creationTime  https://photos.google.com/lr/photo/AF474M0HrxY...   \n",
       " \n",
       "                                                         baseUrl    mimeType  \\\n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_aqb...  image/jpeg   \n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_Yzb...  image/jpeg   \n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_Z9J...  image/jpeg   \n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_YNc...   video/mp4   \n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_Yr6...  image/jpeg   \n",
       " creationTime  https://lh3.googleusercontent.com/lr/ANt_8_Zee...  image/jpeg   \n",
       " \n",
       "                       creationTime                             filename  \n",
       " creationTime  2023-01-28T16:56:14Z           PXL_20230128_165614133.jpg  \n",
       " creationTime  2023-01-28T16:56:11Z        PXL_20230128_165611657.MP.jpg  \n",
       " creationTime  2023-01-28T16:56:02Z        PXL_20230128_165602548.MP.jpg  \n",
       " creationTime  2023-01-28T11:20:03Z           PXL_20230128_111935877.mp4  \n",
       " creationTime  2023-01-28T08:34:13Z  PXL_20230128_083413299.PORTRAIT.jpg  \n",
       " creationTime  2023-01-28T08:34:05Z  PXL_20230128_083405553.PORTRAIT.jpg  )"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_of_media_items(year, month, day, album_id, media_items_df):\n",
    "    '''\n",
    "    Args:\n",
    "        year, month, day, album_id: day for the filter of the API call \n",
    "        media_items_df: existing data frame with all find media items so far\n",
    "    Return:\n",
    "        media_items_df: media items data frame extended by the articles found for the specified tag\n",
    "        items_df: media items uploaded on specified date\n",
    "    '''\n",
    "\n",
    "    items_list_df = pd.DataFrame()\n",
    "    \n",
    "    # create request for specified date\n",
    "    response = get_response_from_medium_api(year, month, day, album_id)\n",
    "\n",
    "    try:\n",
    "        for item in response.json()['mediaItems']:\n",
    "            items_df = pd.DataFrame(item)\n",
    "            items_df = items_df.rename(columns={\"mediaMetadata\": \"creationTime\"})\n",
    "            items_df.set_index('creationTime')\n",
    "            items_df = items_df[items_df.index == 'creationTime']\n",
    "\n",
    "            #append the existing media_items data frame\n",
    "            items_list_df = pd.concat([items_list_df, items_df])\n",
    "            media_items_df = pd.concat([media_items_df, items_df])\n",
    "    \n",
    "    except:\n",
    "        print(response.text)\n",
    "\n",
    "    return(items_list_df, media_items_df)\n",
    "\n",
    "media_items_df = pd.DataFrame()\n",
    "list_of_media_items(2023, 1, 28, album_id, media_items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "DatetimeIndex(['2023-01-07', '2023-01-08', '2023-01-09', '2023-01-10',\n",
      "               '2023-01-11', '2023-01-12', '2023-01-13', '2023-01-14',\n",
      "               '2023-01-15', '2023-01-16', '2023-01-17', '2023-01-18',\n",
      "               '2023-01-19', '2023-01-20', '2023-01-21', '2023-01-22',\n",
      "               '2023-01-23', '2023-01-24', '2023-01-25', '2023-01-26',\n",
      "               '2023-01-27', '2023-01-28', '2023-01-29'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "200\n",
      "{}\n",
      "\n",
      "No media items found for date: 2023 / 1 / 7\n",
      "                                                             id  \\\n",
      "creationTime  AF474M1OmLK_iiYYUBi14HgQdMT6T88IzNonKHq2K0THXm...   \n",
      "creationTime  AF474M2JPeyewl-PmawPOg1howmA_h6DVBuBMXVh5KqI58...   \n",
      "creationTime  AF474M2rbiDvC9qquSXgIo0aRfQuXGYBeczvLBk5UERg2a...   \n",
      "creationTime  AF474M0YvqWv4xiMuGb_T7UioXRf7OyPiuW0l9Yr17bxfS...   \n",
      "creationTime  AF474M3hqEf5fnJAMW_Nqxbp51Sci9PKGY0UqKJLou_8c1...   \n",
      "creationTime  AF474M3rXETVXlWhYQ-Vqi6OL57XAV80m2cj1_WMvlz8PV...   \n",
      "creationTime  AF474M3t-GWlSZFbF2cb2ghW1CwGf0ERe_q3ANDRgW_CMT...   \n",
      "creationTime  AF474M1cypjdQ1dLWKJL7GERinglyE2nRs21G9tILI4PsH...   \n",
      "\n",
      "                                                     productUrl  \\\n",
      "creationTime  https://photos.google.com/lr/photo/AF474M1OmLK...   \n",
      "creationTime  https://photos.google.com/lr/photo/AF474M2JPey...   \n",
      "creationTime  https://photos.google.com/lr/photo/AF474M2rbiD...   \n",
      "creationTime  https://photos.google.com/lr/photo/AF474M0YvqW...   \n",
      "creationTime  https://photos.google.com/lr/photo/AF474M3hqEf...   \n",
      "creationTime  https://photos.google.com/lr/photo/AF474M3rXET...   \n",
      "creationTime  https://photos.google.com/lr/photo/AF474M3t-GW...   \n",
      "creationTime  https://photos.google.com/lr/photo/AF474M1cypj...   \n",
      "\n",
      "                                                        baseUrl    mimeType  \\\n",
      "creationTime  https://lh3.googleusercontent.com/lr/ANt_8_ZkV...  image/jpeg   \n",
      "creationTime  https://lh3.googleusercontent.com/lr/ANt_8_ZL_...  image/jpeg   \n",
      "creationTime  https://lh3.googleusercontent.com/lr/ANt_8_aSO...  image/jpeg   \n",
      "creationTime  https://lh3.googleusercontent.com/lr/ANt_8_boe...  image/jpeg   \n",
      "creationTime  https://lh3.googleusercontent.com/lr/ANt_8_YK0...  image/jpeg   \n",
      "creationTime  https://lh3.googleusercontent.com/lr/ANt_8_b0O...  image/jpeg   \n",
      "creationTime  https://lh3.googleusercontent.com/lr/ANt_8_bzd...  image/jpeg   \n",
      "creationTime  https://lh3.googleusercontent.com/lr/ANt_8_ZHI...  image/jpeg   \n",
      "\n",
      "                      creationTime  \\\n",
      "creationTime  2023-01-08T17:55:17Z   \n",
      "creationTime  2023-01-08T15:14:45Z   \n",
      "creationTime  2023-01-08T15:14:44Z   \n",
      "creationTime  2023-01-08T15:14:42Z   \n",
      "creationTime  2023-01-08T15:14:41Z   \n",
      "creationTime  2023-01-08T15:13:53Z   \n",
      "creationTime  2023-01-08T15:13:44Z   \n",
      "creationTime  2023-01-08T15:13:44Z   \n",
      "\n",
      "                                                       filename  \n",
      "creationTime                            IMG-20230108-WA0011.jpg  \n",
      "creationTime                         PXL_20230108_151445978.jpg  \n",
      "creationTime                         PXL_20230108_151444222.jpg  \n",
      "creationTime                         PXL_20230108_151442891.jpg  \n",
      "creationTime                         PXL_20230108_151441478.jpg  \n",
      "creationTime                         PXL_20230108_151353940.jpg  \n",
      "creationTime                      PXL_20230108_151344562.MP.jpg  \n",
      "creationTime  PXL_20230108_151344562_exported_599_1673200661...  \n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/bruno/git/photo_syncing/google-photos-api/google_api_test.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bruno/git/photo_syncing/google-photos-api/google_api_test.ipynb#X10sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(items_df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bruno/git/photo_syncing/google-photos-api/google_api_test.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(files_list_df)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bruno/git/photo_syncing/google-photos-api/google_api_test.ipynb#X10sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m items_not_yet_downloaded_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(items_df, files_list_df,on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfilename\u001b[39;49m\u001b[39m'\u001b[39;49m,how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bruno/git/photo_syncing/google-photos-api/google_api_test.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m items_not_yet_downloaded_df\u001b[39m.\u001b[39mhead(\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bruno/git/photo_syncing/google-photos-api/google_api_test.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# download all items in items_not_yet_downloaded\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/photo_sync/lib/python3.10/site-packages/pandas/core/reshape/merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m--> 107\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    108\u001b[0m         left,\n\u001b[1;32m    109\u001b[0m         right,\n\u001b[1;32m    110\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m    111\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m    112\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[1;32m    113\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[1;32m    114\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[1;32m    115\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[1;32m    116\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    117\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[1;32m    118\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    119\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[1;32m    120\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    121\u001b[0m     )\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniconda3/envs/photo_sync/lib/python3.10/site-packages/pandas/core/reshape/merge.py:700\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cross \u001b[39m=\u001b[39m cross_col\n\u001b[1;32m    695\u001b[0m \u001b[39m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    696\u001b[0m (\n\u001b[1;32m    697\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys,\n\u001b[1;32m    698\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys,\n\u001b[1;32m    699\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_names,\n\u001b[0;32m--> 700\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_merge_keys()\n\u001b[1;32m    702\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m~/miniconda3/envs/photo_sync/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1097\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_rkey(rk):\n\u001b[1;32m   1096\u001b[0m     \u001b[39mif\u001b[39;00m rk \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1097\u001b[0m         right_keys\u001b[39m.\u001b[39mappend(right\u001b[39m.\u001b[39;49m_get_label_or_level_values(rk))\n\u001b[1;32m   1098\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m         \u001b[39m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m         right_keys\u001b[39m.\u001b[39mappend(right\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/photo_sync/lib/python3.10/site-packages/pandas/core/generic.py:1840\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1838\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mget_level_values(key)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1839\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1842\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'filename'"
     ]
    }
   ],
   "source": [
    "# getting data for a a specific date up to now\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta, datetime\n",
    "import requests\n",
    "\n",
    "# Images should only be downloaded if they are not already available in downloads\n",
    "# Herefor the following code snippet, creates a list with all filenames in the /downloads/ folder\n",
    "files_list = os.listdir(r'./downloads')\n",
    "files_list_df = pd.DataFrame(files_list)\n",
    "files_list_df = files_list_df.rename(columns={0: \"filename\"})\n",
    "print(files_list_df.head(2))\n",
    "\n",
    "# create a list with all dates between start date and today\n",
    "sdate = date(2023,1,7)   # start date\n",
    "edate = date.today()\n",
    "date_list = pd.date_range(sdate,edate-timedelta(days=1),freq='d')\n",
    "print(date_list)\n",
    "\n",
    "# name of the album\n",
    "album_id = getAlbum(\"Sync Flickr\")\n",
    "\n",
    "media_items_df = pd.DataFrame()\n",
    "\n",
    "for date in date_list:\n",
    "    \n",
    "    # get a list with all media items for specified date (year, month, day)\n",
    "    items_df, media_items_df = list_of_media_items(year = date.year, month = date.month, day = date.day, album_id=album_id,  media_items_df = media_items_df)\n",
    "\n",
    "    if len(items_df) > 0:\n",
    "        # full outer join of items_df and files_list_df, the result is a list of items of the given \n",
    "        #day that have not been downloaded yet\n",
    "        print(items_df)\n",
    "        print(files_list_df)\n",
    "        if len(files_list_df.df) > 0:\n",
    "            items_not_yet_downloaded_df = pd.merge(items_df, files_list_df,on='filename',how='left')\n",
    "            items_not_yet_downloaded_df.head(2)\n",
    "        else:\n",
    "            items_not_yet_downloaded_df = items_df\n",
    "\n",
    "        # download all items in items_not_yet_downloaded\n",
    "        for index, item in items_not_yet_downloaded_df.iterrows():\n",
    "            url = item.baseUrl + \"=d\" #the =d is for downloading using all metadata\n",
    "            response = requests.get(url)\n",
    "\n",
    "            file_name = item.filename\n",
    "            destination_folder = './downloads/'\n",
    "\n",
    "            with open(os.path.join(destination_folder, file_name), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "                f.close()\n",
    "                \n",
    "        print(f'Downloaded items for date: {date.year} / {date.month} / {date.day}')\n",
    "    else:\n",
    "        print(f'No media items found for date: {date.year} / {date.month} / {date.day}')\n",
    "            \n",
    "#save a list of all media items to a csv file\n",
    "current_datetime = str(datetime.now())\n",
    "filename = f'item-list-{current_datetime}.csv'\n",
    "\n",
    "#save a list with all items in specified time frame\n",
    "media_items_df.to_csv(f'./media_items_list/{filename}', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('photo_sync')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "993c687acff4d36a92770ecb368a1e4daa4eb69b5430147f4a90e2b91c6cb5f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
