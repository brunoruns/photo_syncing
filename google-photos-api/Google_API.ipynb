{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79cf8d79",
   "metadata": {},
   "source": [
    "## Google Photos API - Download images from Google Photos using Python\n",
    "\n",
    "Using the Google Photos REST API you can download, upload and modify images stored in Google Photos.\n",
    "\n",
    "The following steps describe how to set up a simple project that lets you use Python to download images from Google Photos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac8f7c-932d-486f-900b-9fe3fa178138",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create virtualenv and install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6927380f-c820-4ef4-8f32-e68cbf500709",
   "metadata": {},
   "source": [
    "1. Open the terminal and navigate to your working directory. The folder structure of the repo includes the following directories:\n",
    "\n",
    "    * **credentials**: folder to store the credentials you need to authenticate your \"Python App\" to the Google Photos Library\n",
    "    * **media_items_list**: every time the script runs, I want to save a .csv file with all Google Photos media items and the corresponding metadata uploaded in the defined time period\n",
    "    * **downloads**: storing downloaded images from Google Photos\n",
    "\n",
    "\n",
    "2. Create a virtual environment `python3 -m venv venv`, activate it `. ./venv/bin/activate` and install requirements `pip install -r requirements.txt`\n",
    "\n",
    "3. Install ipykernel which provides the IPython kernel for Jupyter: `pip install ipykernel` and add your virtual environment to Jupyter: `python -m ipykernel install --user --name=venv` \n",
    "\n",
    "    You can check the installation by navigating to /Users/<user>/Library/Jupyter/kernels. There should be a new directory called 'venv'. In the folder you can find the file 'kernel.json', which contains the path for the used python installation is defined.\n",
    "\n",
    "4. Start jupyter notebook or jupyter lab: `jupyter lab .` and select the just created environment \"venv\" as Kernel\n",
    "\n",
    "![](read_me_img/select_kernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5434000b-35ff-4aa2-a8b8-cc9a26f548d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enable Google API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa3746-d4a0-4795-8e5a-226490d6e554",
   "metadata": {},
   "source": [
    "5. Enable Google Photos API Service\n",
    "\n",
    "   1. Go to the Google API Console [https://console.cloud.google.com/](https://console.cloud.google.com/). \n",
    "   2. From the menu bar, select a project or create a new project.\n",
    "   \n",
    "      ![](read_me_img/gifs/create_new_project_speed.gif)\n",
    "      \n",
    "   3. To open the Google API Library, from the Navigation menu, select APIs & Services > Library. \n",
    "   4. Search for \"Google Photos Library API\". Select the correct result and click \"enable\". If its already enabled, click \"manage\"\n",
    "   \n",
    "       ![](read_me_img/gifs/enable_api_speed.gif)\n",
    "       \n",
    "   5. Afterwards it will forward you to the \"Photos API/Service details\" page (https://console.cloud.google.com/apis/credentials)\n",
    "\n",
    "\n",
    "6. Configure \"OAuth consent screen\" ([Source](https://stackoverflow.com/questions/65184355/error-403-access-denied-from-google-authentication-web-api-despite-google-acc))\n",
    "\n",
    "   1. Go back to the Photos API Service details page and click on \"[OAuth consent screen](https://console.cloud.google.com/apis/credentials/consent)\" on the left side (below \"Credentials\") \n",
    "   2. Add a Test user: Use the email of the account you want to use for testing the API call\n",
    "   \n",
    "        ![](read_me_img/add_test_user.png)\n",
    "\n",
    "7. Create API/OAuth credentials\n",
    "\n",
    "   1. On the left side of the Google Photos API Service page, click Credentials\n",
    "   2. Click on \"Create Credentials\" and create a OAuth client ID\n",
    "   3. As application type I am choosing \"Desktop app\" and give your client you want to use to call the API a name\n",
    "   4. Download the JSON file to the created credentials, rename it to \"client_secret.json\" and save it in the folder \"credentials\"\n",
    "   \n",
    "        ![](read_me_img/gifs/create_credentials_speed.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290cacec-9573-488d-89a2-67bb22814d69",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install and import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7c7c7-9d39-4b7e-842d-5dadc7a79e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt \n",
    "#saves the output to variable capt, to print output capt.stdout, capt.stderr\n",
    "!pip install -r \"requirements.txt\"\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85475dc1-1cb4-466a-88a7-2a756faa747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python\n",
    "!which pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498c8c38-d525-462d-b3e6-a16b9da9c7a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use the Google Photo Library API for the first time:\n",
    "\n",
    "The following section shows how to use OAuth Credentials for authentication with the Google Library API. The code section below covers the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d724f-c302-4d5f-b3be-9341a4a0fc84",
   "metadata": {},
   "source": [
    "8. Create a service for the first time:\n",
    "\n",
    "    1. Initialize GooglePhotosApi `google_photos_api = GooglePhotosApi()`\n",
    "\n",
    "    2. Create Service using the `client_secret.json` file: `service = google_photos_api.create_service()`\n",
    "        \n",
    "        \n",
    "       <b>Calling the API for the first time:</b>\n",
    "       1. Google will ask you if you want to grant the App the required permissions you defined with the scope:\n",
    "       ![](read_me_img/sign_in_google_acc.png)\n",
    "       2. Since its just a test app at the moment, Google will make you aware of that > Click on \"Continue\"\n",
    "       3. Once you granted the app the required permissions, you will see a \"token_......pickle\" file created in the folder \"credentials\". This token file will be used for future calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e55f6c-d7a8-4541-961e-b28a768eeec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from google_auth_oauthlib.flow import Flow, InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "#from googleapiclient.http import MediaFileUpload\n",
    "from google.auth.transport.requests import Request\n",
    "import requests\n",
    "\n",
    "class GooglePhotosApi:\n",
    "    def __init__(self,\n",
    "                 api_name = 'photoslibrary',\n",
    "                 client_secret_file= r'./credentials/client_secret.json',\n",
    "                 api_version = 'v1',\n",
    "                 scopes = ['https://www.googleapis.com/auth/photoslibrary']):\n",
    "        '''\n",
    "        Args:\n",
    "            client_secret_file: string, location where the requested credentials are saved\n",
    "            api_version: string, the version of the service\n",
    "            api_name: string, name of the api e.g.\"docs\",\"photoslibrary\",...\n",
    "            api_version: version of the api\n",
    "\n",
    "        Return:\n",
    "            service:\n",
    "        '''\n",
    "\n",
    "        self.api_name = api_name\n",
    "        self.client_secret_file = client_secret_file\n",
    "        self.api_version = api_version\n",
    "        self.scopes = scopes\n",
    "        self.cred_pickle_file = f'./credentials/token_{self.api_name}_{self.api_version}.pickle'\n",
    "\n",
    "        self.cred = None\n",
    "\n",
    "    def run_local_server(self):\n",
    "        # is checking if there is already a pickle file with relevant credentials\n",
    "        if os.path.exists(self.cred_pickle_file):\n",
    "            with open(self.cred_pickle_file, 'rb') as token:\n",
    "                self.cred = pickle.load(token)\n",
    "\n",
    "        # if there is no pickle file with stored credentials, create one using google_auth_oauthlib.flow\n",
    "        if not self.cred or not self.cred.valid:\n",
    "            if self.cred and self.cred.expired and self.cred.refresh_token:\n",
    "                self.cred.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(self.client_secret_file, self.scopes)\n",
    "                self.cred = flow.run_local_server()\n",
    "\n",
    "            with open(self.cred_pickle_file, 'wb') as token:\n",
    "                pickle.dump(self.cred, token)\n",
    "        \n",
    "        return self.cred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f0efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize photos api and create service\n",
    "google_photos_api = GooglePhotosApi()\n",
    "creds = google_photos_api.run_local_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb37b37d-9c1c-4c88-9f4f-4f2eeefc3c3a",
   "metadata": {},
   "source": [
    "### Use pythons requests module and the token file to retrieve data from Google Photos\n",
    "\n",
    "9. Use requests python module to send http requests to the Media Items API\n",
    "\n",
    "    The following function sends a post request to the Media API to get a list of all entries. Since the API return is limited to 100 items, the search is narrowed down to one day. Thus, the call would only be a problem if more than 100 images were created/uploaded on one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ee5847-923b-40f1-87cd-4b935dbd328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def get_response_from_medium_api(year, month, day):\n",
    "    url = 'https://photoslibrary.googleapis.com/v1/mediaItems:search'\n",
    "    payload = {\n",
    "                  \"filters\": {\n",
    "                    \"dateFilter\": {\n",
    "                      \"dates\": [\n",
    "                        {\n",
    "                          \"day\": day,\n",
    "                          \"month\": month,\n",
    "                          \"year\": year\n",
    "                        }\n",
    "                      ]\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "    headers = {\n",
    "        'content-type': 'application/json',\n",
    "        'Authorization': 'Bearer {}'.format(creds.token)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        res = requests.request(\"POST\", url, data=json.dumps(payload), headers=headers)\n",
    "    except:\n",
    "        print('Request error') \n",
    "    \n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a38726-10aa-47d8-9f57-4d575ce57193",
   "metadata": {},
   "source": [
    "Use the response of the API to write the results and required metadata into a data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd790ac-1a44-4f79-afb9-1d6621c3f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_media_items(year, month, day, media_items_df):\n",
    "    '''\n",
    "    Args:\n",
    "        year, month, day: day for the filter of the API call \n",
    "        media_items_df: existing data frame with all find media items so far\n",
    "    Return:\n",
    "        media_items_df: media items data frame extended by the articles found for the specified tag\n",
    "        items_df: media items uploaded on specified date\n",
    "    '''\n",
    "\n",
    "    items_list_df = pd.DataFrame()\n",
    "    \n",
    "    # create request for specified date\n",
    "    response = get_response_from_medium_api(year, month, day)\n",
    "\n",
    "    try:\n",
    "        for item in response.json()['mediaItems']:\n",
    "            items_df = pd.DataFrame(item)\n",
    "            items_df = items_df.rename(columns={\"mediaMetadata\": \"creationTime\"})\n",
    "            items_df.set_index('creationTime')\n",
    "            items_df = items_df[items_df.index == 'creationTime']\n",
    "\n",
    "            #append the existing media_items data frame\n",
    "            items_list_df = pd.concat([items_list_df, items_df])\n",
    "            media_items_df = pd.concat([media_items_df, items_df])\n",
    "    \n",
    "    except:\n",
    "        print(response.text)\n",
    "\n",
    "    return(items_list_df, media_items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc1dda-4145-4c84-94ac-f8b634f794cd",
   "metadata": {},
   "source": [
    "## Use the defined functions to download media items from Google Photos\n",
    "\n",
    "1. Create a list with all files already downloaded to the /downloads/ folder\n",
    "2. Define a list of all dates from start date to end date (today)\n",
    "3. Execute the API call for all dates to get a list with all media items. API returns:\n",
    "    * **id**\n",
    "    * **filename**\n",
    "    * **baseUrl**: Base URLs within the Google Photos Library API allow you to access the bytes of the media items. They are valid for 60 minutes. (https://developers.google.com/photos/library/guides/access-media-items)\n",
    "\n",
    "\n",
    "4. Compare list of media items with files downloaded in /downloads/ with media items in Google Photos, to download items which are not downloaded yet. You can now use the baseUrl and the python requests module to send a get request for each media item.\n",
    "5. Save a list as with all media items as .csv in /media_items_list/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cadce4a-cb1c-4fb4-affb-3eb40ac7efbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2021-04-16', '2021-04-17', '2021-04-18', '2021-04-19',\n",
      "               '2021-04-20', '2021-04-21', '2021-04-22', '2021-04-23',\n",
      "               '2021-04-24', '2021-04-25',\n",
      "               ...\n",
      "               '2022-05-12', '2022-05-13', '2022-05-14', '2022-05-15',\n",
      "               '2022-05-16', '2022-05-17', '2022-05-18', '2022-05-19',\n",
      "               '2022-05-20', '2022-05-21'],\n",
      "              dtype='datetime64[ns]', length=401, freq='D')\n",
      "{}\n",
      "\n",
      "No media items found for date: 2021 / 4 / 16\n",
      "Downloaded items found for date: 2021 / 4 / 17\n",
      "Downloaded items found for date: 2021 / 4 / 18\n",
      "Downloaded items found for date: 2021 / 4 / 19\n",
      "{}\n",
      "\n",
      "No media items found for date: 2021 / 4 / 20\n",
      "Downloaded items found for date: 2021 / 4 / 21\n",
      "Downloaded items found for date: 2021 / 4 / 22\n",
      "Downloaded items found for date: 2021 / 4 / 23\n",
      "Request error\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'res' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m media_items_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_list:\n\u001b[1;32m     21\u001b[0m     \n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# get a list with all media items for specified date (year, month, day)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     items_df, media_items_df \u001b[38;5;241m=\u001b[39m \u001b[43mlist_of_media_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mday\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmedia_items_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmedia_items_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(items_df) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m# full outer join of items_df and files_list_df, the result is a list of items of the given \u001b[39;00m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;66;03m#day that have not been downloaded yet\u001b[39;00m\n\u001b[1;32m     28\u001b[0m         items_not_yet_downloaded_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(items_df, files_list_df,on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mlist_of_media_items\u001b[0;34m(year, month, day, media_items_df)\u001b[0m\n\u001b[1;32m     11\u001b[0m items_list_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# create request for specified date\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_response_from_medium_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmediaItems\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mget_response_from_medium_api\u001b[0;34m(year, month, day)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRequest error\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[43mres\u001b[49m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'res' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, timedelta, datetime\n",
    "import requests\n",
    "\n",
    "# Images should only be downloaded if they are not already available in downloads\n",
    "# Herefor the following code snippet, creates a list with all filenames in the /downloads/ folder\n",
    "files_list = os.listdir(r'./downloads')\n",
    "files_list_df = pd.DataFrame(files_list)\n",
    "files_list_df = files_list_df.rename(columns={0: \"filename\"})\n",
    "files_list_df.head(2)\n",
    "\n",
    "# create a list with all dates between start date and today\n",
    "sdate = date(2021,4,16)   # start date\n",
    "edate = date.today()\n",
    "date_list = pd.date_range(sdate,edate-timedelta(days=1),freq='d')\n",
    "print(date_list)\n",
    "\n",
    "media_items_df = pd.DataFrame()\n",
    "\n",
    "for date in date_list:\n",
    "    \n",
    "    # get a list with all media items for specified date (year, month, day)\n",
    "    items_df, media_items_df = list_of_media_items(year = date.year, month = date.month, day = date.day, media_items_df = media_items_df)\n",
    "\n",
    "    if len(items_df) > 0:\n",
    "        # full outer join of items_df and files_list_df, the result is a list of items of the given \n",
    "        #day that have not been downloaded yet\n",
    "        items_not_yet_downloaded_df = pd.merge(items_df, files_list_df,on='filename',how='left')\n",
    "        items_not_yet_downloaded_df.head(2)\n",
    "\n",
    "        # download all items in items_not_yet_downloaded\n",
    "        for index, item in items_not_yet_downloaded_df.iterrows():\n",
    "            url = item.baseUrl\n",
    "            response = requests.get(url)\n",
    "\n",
    "            file_name = item.filename\n",
    "            destination_folder = './downloads/'\n",
    "\n",
    "            with open(os.path.join(destination_folder, file_name), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "                f.close()\n",
    "                \n",
    "        print(f'Downloaded items found for date: {date.year} / {date.month} / {date.day}')\n",
    "    else:\n",
    "        print(f'No media items found for date: {date.year} / {date.month} / {date.day}')\n",
    "            \n",
    "#save a list of all media items to a csv file\n",
    "current_datetime = str(datetime.now())\n",
    "filename = f'item-list-{current_datetime}.csv'\n",
    "\n",
    "#save a list with all items in specified time frame\n",
    "media_items_df.to_csv(f'./media_items_list/{filename}', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c82c89bc-f002-4ec8-be8a-57ff1a86bded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 2595340] update jupyter notebook\n",
      " 36 files changed, 699 insertions(+), 149 deletions(-)\n",
      " create mode 100644 venv_google/bin/Activate.ps1\n",
      " create mode 100644 venv_google/bin/activate\n",
      " create mode 100644 venv_google/bin/activate.csh\n",
      " create mode 100644 venv_google/bin/activate.fish\n",
      " create mode 100755 venv_google/bin/f2py\n",
      " create mode 100755 venv_google/bin/f2py3\n",
      " create mode 100755 venv_google/bin/f2py3.10\n",
      " create mode 100755 venv_google/bin/google-oauthlib-tool\n",
      " create mode 100755 venv_google/bin/ipython\n",
      " create mode 100755 venv_google/bin/ipython3\n",
      " create mode 100755 venv_google/bin/jupyter\n",
      " create mode 100755 venv_google/bin/jupyter-kernel\n",
      " create mode 100755 venv_google/bin/jupyter-kernelspec\n",
      " create mode 100755 venv_google/bin/jupyter-migrate\n",
      " create mode 100755 venv_google/bin/jupyter-run\n",
      " create mode 100755 venv_google/bin/jupyter-troubleshoot\n",
      " create mode 100755 venv_google/bin/normalizer\n",
      " create mode 100755 venv_google/bin/pip\n",
      " create mode 100755 venv_google/bin/pip3\n",
      " create mode 100755 venv_google/bin/pip3.10\n",
      " create mode 100755 venv_google/bin/pygmentize\n",
      " create mode 100755 venv_google/bin/pyrsa-decrypt\n",
      " create mode 100755 venv_google/bin/pyrsa-encrypt\n",
      " create mode 100755 venv_google/bin/pyrsa-keygen\n",
      " create mode 100755 venv_google/bin/pyrsa-priv2pub\n",
      " create mode 100755 venv_google/bin/pyrsa-sign\n",
      " create mode 100755 venv_google/bin/pyrsa-verify\n",
      " create mode 120000 venv_google/bin/python\n",
      " create mode 120000 venv_google/bin/python3\n",
      " create mode 120000 venv_google/bin/python3.10\n",
      " create mode 100644 venv_google/pyvenv.cfg\n",
      " create mode 100644 venv_google/share/jupyter/kernels/python3/kernel.json\n",
      " create mode 100644 venv_google/share/jupyter/kernels/python3/logo-32x32.png\n",
      " create mode 100644 venv_google/share/jupyter/kernels/python3/logo-64x64.png\n",
      " create mode 100644 venv_google/share/man/man1/ipython.1\n",
      "Enumerating objects: 42, done.\n",
      "Counting objects: 100% (42/42), done.\n",
      "Delta compression using up to 8 threads\n",
      "Compressing objects: 100% (35/35), done.\n",
      "Writing objects: 100% (40/40), 12.45 KiB | 4.15 MiB/s, done.\n",
      "Total 40 (delta 19), reused 13 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (19/19), completed with 2 local objects.\u001b[K\n",
      "To github.com:polzerdo55862/google-photos-api.git\n",
      "   4405592..2595340  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git config --global user.email \"dmnkplzr@googlemail.com\"\n",
    "!git config --global user.name \"Dominik Polzer\"\n",
    "!git add .\n",
    "!git commit -m \"update jupyter notebook\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b0078-8f56-4b2b-a3cb-2d433be9ee4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
